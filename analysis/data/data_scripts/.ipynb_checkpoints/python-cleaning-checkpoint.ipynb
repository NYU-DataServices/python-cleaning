{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Management Using Python\n",
    "\n",
    "**Nicholas Wolf and Vicky Steeves, NYU Data Services**\n",
    "\n",
    "Vicky's ORCID: 0000-0003-4298-168X | Nick's ORCID: 0000-0001-5512-6151\n",
    "\n",
    "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.\n",
    "\n",
    "**Overview**\n",
    "\n",
    "This session is an intermediate level class that will examine ways to perform data cleaning, transformation, and management using Python. We will look at some helpful ways to load data and parse it into a container for ease of use in Python, to store it in helpful formats, and to perform some basic cleaning and transformations typical for mixed string-and-numeric formats. Finally, we'll try putting it all together using a dataset form the NYC Open Data portal.\n",
    "\n",
    "**Setup**\n",
    "\n",
    "Let's think about helpful project organizational structures from the start. We can borrow a helpful folder structure used by Ben Marwick in his <a href=\"https://github.com/benmarwick/rrtools\">rrtools</a> R package. There are iterations of this idea in a lot of places, but the basic idea is to separate your starting data from your transformed/cleaned data, and all of this input data from your subsequent analysis, documentation, and outputs. We'll modify his tree directory slightly:\n",
    "\n",
    "<pre>analysis/\n",
    "|\n",
    "├── paper/              # Working paper for publication\n",
    "│\n",
    "│\n",
    "├── figures/            # location of the figures produced by your analysis\n",
    "|\n",
    "├── data/\n",
    "|   ├── data_scripts/   # scripts used to transform and clean raw data\n",
    "│   ├── raw_data/       # data obtained by you or from elsewhere\n",
    "|   └── cleaned_data/   # migrated format versions of raw data, with syntax corrections and integrity checks \n",
    "|\n",
    "└── docs                # documentation files for methods, parameters, data dictionaries, etc.</pre>\n",
    "\n",
    "\n",
    "Download the zipped folder package available at <a href=\"https://goo.gl/SJUrcJ\">goo.gl/SJUrcJ</a> and place it on your desktop. Uncompress the files. We'll be working with the Jupyter Notebook located at /analysis/data/data_scripts/python-cleaning.ipynb. Alternately, you can clone the course materials using \n",
    "\n",
    "<code>git clone https\\://github\\.com/NYU-DataServices\\/python-cleaning\\.git</code>\n",
    "\n",
    "You can also find this notebook (in non-executable form) at <a href=\"https://nyu-dataservices.github.io/python-cleaning/\">https://nyu-dataservices.github.io/python-cleaning/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Parsing\n",
    "\n",
    "**1. CSV and Dataframes**\n",
    "\n",
    "Not surprisingly, a very common and helpful way to store data is in CSV format. Most applications have some way of working with delimited files, and while not 100% standardized, CSVs provide a stable means of sharing and storing dat of all types.\n",
    "\n",
    "Python offers a <a href=\"https://docs.python.org/3/library/csv.html\">CSV module</a>, but it can be a wordy way to input and output data into your workflow. Since analysis is also often eased by using a more complex data container such as a dataframe, let's rely on the Pandas module to do the heavy lifting of importing (and later exporting) CSVs.\n",
    "\n",
    "Here, we load up a CSV storing NYC <a href=\"https://data.cityofnewyork.us/Environment/Water-Consumption-In-The-New-York-City/ia2d-e54m\">water consumption data</a> from the NYC Open Data portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>New York City Population</th>\n",
       "      <th>NYC Consumption(Million gallons per day)</th>\n",
       "      <th>Per Capita(Gallons per person per day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>7102100</td>\n",
       "      <td>1512</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980</td>\n",
       "      <td>7071639</td>\n",
       "      <td>1506</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981</td>\n",
       "      <td>7089241</td>\n",
       "      <td>1309</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1982</td>\n",
       "      <td>7109105</td>\n",
       "      <td>1382</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1983</td>\n",
       "      <td>7181224</td>\n",
       "      <td>1424</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1984</td>\n",
       "      <td>7234514</td>\n",
       "      <td>1465</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1985</td>\n",
       "      <td>7274054</td>\n",
       "      <td>1326</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1986</td>\n",
       "      <td>7319246</td>\n",
       "      <td>1351</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1987</td>\n",
       "      <td>7342476</td>\n",
       "      <td>1447</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1988</td>\n",
       "      <td>7353719</td>\n",
       "      <td>1484</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1989</td>\n",
       "      <td>7344175</td>\n",
       "      <td>1402</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1990</td>\n",
       "      <td>7335650</td>\n",
       "      <td>1424</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1991</td>\n",
       "      <td>7374501</td>\n",
       "      <td>1469</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1992</td>\n",
       "      <td>7428944</td>\n",
       "      <td>1369</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1993</td>\n",
       "      <td>7506166</td>\n",
       "      <td>1369</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1994</td>\n",
       "      <td>7570458</td>\n",
       "      <td>1358</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1995</td>\n",
       "      <td>7633040</td>\n",
       "      <td>1326</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1996</td>\n",
       "      <td>7697812</td>\n",
       "      <td>1298</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1997</td>\n",
       "      <td>7773443</td>\n",
       "      <td>1206</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1998</td>\n",
       "      <td>7858259</td>\n",
       "      <td>1220</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1999</td>\n",
       "      <td>7947660</td>\n",
       "      <td>1237</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2000</td>\n",
       "      <td>8008278</td>\n",
       "      <td>1240</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2001</td>\n",
       "      <td>8024964</td>\n",
       "      <td>1184</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2002</td>\n",
       "      <td>8041649</td>\n",
       "      <td>1136</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2003</td>\n",
       "      <td>8058335</td>\n",
       "      <td>1094</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2004</td>\n",
       "      <td>8075020</td>\n",
       "      <td>1100</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2005</td>\n",
       "      <td>8091706</td>\n",
       "      <td>1138</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2006</td>\n",
       "      <td>8108391</td>\n",
       "      <td>1069</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2007</td>\n",
       "      <td>8125077</td>\n",
       "      <td>1114</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2008</td>\n",
       "      <td>8141762</td>\n",
       "      <td>1098</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2009</td>\n",
       "      <td>8158448</td>\n",
       "      <td>1007</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2010</td>\n",
       "      <td>8175133</td>\n",
       "      <td>1039</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2011</td>\n",
       "      <td>8175133</td>\n",
       "      <td>1021</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2012</td>\n",
       "      <td>8336697</td>\n",
       "      <td>1009</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2013</td>\n",
       "      <td>8405837</td>\n",
       "      <td>1006</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2014</td>\n",
       "      <td>8491079</td>\n",
       "      <td>996</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2015</td>\n",
       "      <td>8550405</td>\n",
       "      <td>1009</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2016</td>\n",
       "      <td>8537673</td>\n",
       "      <td>1002</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  New York City Population  NYC Consumption(Million gallons per day)  \\\n",
       "0   1979                   7102100                                      1512   \n",
       "1   1980                   7071639                                      1506   \n",
       "2   1981                   7089241                                      1309   \n",
       "3   1982                   7109105                                      1382   \n",
       "4   1983                   7181224                                      1424   \n",
       "5   1984                   7234514                                      1465   \n",
       "6   1985                   7274054                                      1326   \n",
       "7   1986                   7319246                                      1351   \n",
       "8   1987                   7342476                                      1447   \n",
       "9   1988                   7353719                                      1484   \n",
       "10  1989                   7344175                                      1402   \n",
       "11  1990                   7335650                                      1424   \n",
       "12  1991                   7374501                                      1469   \n",
       "13  1992                   7428944                                      1369   \n",
       "14  1993                   7506166                                      1369   \n",
       "15  1994                   7570458                                      1358   \n",
       "16  1995                   7633040                                      1326   \n",
       "17  1996                   7697812                                      1298   \n",
       "18  1997                   7773443                                      1206   \n",
       "19  1998                   7858259                                      1220   \n",
       "20  1999                   7947660                                      1237   \n",
       "21  2000                   8008278                                      1240   \n",
       "22  2001                   8024964                                      1184   \n",
       "23  2002                   8041649                                      1136   \n",
       "24  2003                   8058335                                      1094   \n",
       "25  2004                   8075020                                      1100   \n",
       "26  2005                   8091706                                      1138   \n",
       "27  2006                   8108391                                      1069   \n",
       "28  2007                   8125077                                      1114   \n",
       "29  2008                   8141762                                      1098   \n",
       "30  2009                   8158448                                      1007   \n",
       "31  2010                   8175133                                      1039   \n",
       "32  2011                   8175133                                      1021   \n",
       "33  2012                   8336697                                      1009   \n",
       "34  2013                   8405837                                      1006   \n",
       "35  2014                   8491079                                       996   \n",
       "36  2015                   8550405                                      1009   \n",
       "37  2016                   8537673                                      1002   \n",
       "\n",
       "    Per Capita(Gallons per person per day)  \n",
       "0                                      213  \n",
       "1                                      213  \n",
       "2                                      185  \n",
       "3                                      194  \n",
       "4                                      198  \n",
       "5                                      203  \n",
       "6                                      182  \n",
       "7                                      185  \n",
       "8                                      197  \n",
       "9                                      202  \n",
       "10                                     191  \n",
       "11                                     194  \n",
       "12                                     199  \n",
       "13                                     184  \n",
       "14                                     182  \n",
       "15                                     179  \n",
       "16                                     174  \n",
       "17                                     169  \n",
       "18                                     155  \n",
       "19                                     155  \n",
       "20                                     156  \n",
       "21                                     155  \n",
       "22                                     148  \n",
       "23                                     141  \n",
       "24                                     136  \n",
       "25                                     136  \n",
       "26                                     141  \n",
       "27                                     132  \n",
       "28                                     137  \n",
       "29                                     135  \n",
       "30                                     123  \n",
       "31                                     127  \n",
       "32                                     125  \n",
       "33                                     121  \n",
       "34                                     120  \n",
       "35                                     117  \n",
       "36                                     118  \n",
       "37                                     117  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "## Set a working directory for our /data parent directory\n",
    "## Mac\n",
    "directory = r'../'\n",
    "## Windows\n",
    "#directory = r'..\\data\\\\'\n",
    "\n",
    "# Load a CSV into a data frame\n",
    "df = pd.read_csv(directory + 'raw_data/water-consumption-nyc.csv', header=0, \n",
    "                 sep=',', parse_dates=False, encoding='utf-8')\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. JSON**\n",
    "\n",
    "Python's json module is compact and easy to use. Once loaded, the JSON object is treated as a full-fledged JSON dictionary. Let's load the same data on water consumption stored as a JSON file. You can preview the NYC JSON structure here: https://data.cityofnewyork.us/api/views/ia2d-e54m/rows.json?accessType=DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "water_dictionary = json.loads(open(directory + 'raw_data/water-consumption-nyc.json', encoding='utf-8').read())\n",
    "\n",
    "## We can take a look at the data portion of the file (rather than the metadata stored in the JSON)\n",
    "\n",
    "for row in water_dictionary['data']:\n",
    "    print(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus**\n",
    "\n",
    "Let's turn the list of lists in which NYC has stored the data into a dataframe. Because the data has been stored as a list of lists, this is a one-step process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_df = pd.DataFrame(water_dictionary['data'])\n",
    "\n",
    "display(water_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "We've lost our column headers! NYC has stored them in a separate location in the JSON. How can we recover them? Hint: take a look at the full JSON here: https://data.cityofnewyork.us/api/views/ia2d-e54m/rows.json?accessType=DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. SQLite**\n",
    "\n",
    "Once you start working with data distributed across multiple tables, or working with data that is starting to exceed easy usability in a format like CSV, consider implementing Python with a simple SQLite database to push and pull data. The maintainers of SQLite3 claim that it will operate on large data files (see https://www.sqlite.org/limits.html), up to 140 TB of file size for a database--larger than most systems can manipulate in memory, at any rate. So for most purposes, you can nicely store your data in such a database and access it when needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Create a connection object to our sqlite3 database file\n",
    "\n",
    "conn = sqlite3.connect(directory + 'raw_data/water-consumption.db')\n",
    "\n",
    "c = conn.cursor()\n",
    "\n",
    "# Select data from the water table\n",
    "\n",
    "rows = c.execute(\"SELECT * FROM water\")\n",
    "\n",
    "# The response is a list of tuples, each tuple containing a cell values\n",
    "\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can modify our data\n",
    "\n",
    "newrow = ('2017', '85312743', '1003', '158')\n",
    "\n",
    "c.execute(\"INSERT INTO water VALUES (?,?,?,?)\", newrow)\n",
    "\n",
    "# Commit the changes\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# View the new row\n",
    "\n",
    "rows = c.execute(\"SELECT * FROM water\")\n",
    "\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or...we can once again just read our SQLite table directly into a dataframe:\n",
    "\n",
    "water_sql_df = pd.read_sql_query(\"SELECT * FROM water\", conn)\n",
    "\n",
    "display(water_sql_df)\n",
    "\n",
    "\n",
    "#Close the connnection\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Numpy Array**\n",
    "\n",
    "The numpy module provides a quick way to save complex array-like objects (lists, lists of lists, dictionaries, lists of dictionaries, dictionaries of lists) to a binary-file type .npy file. This can be a quick and easy way (among many others, including saving such objects in a .txt or as a .py file) to save and return to a data container without having to reconstruct it every time you work on a workflow. See also below for how to save the .npy file in the first place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Loading an array from the .npy file\n",
    "\n",
    "water_npy = np.load(directory + '/raw_data/water_consumption.npy')\n",
    "\n",
    "print(water_npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing\n",
    "\n",
    "We've just discussed how to load and parse stored data. Let's look at the opposite side of the coin -- storing data from Python into a saved file.\n",
    "\n",
    "**1. JSON**\n",
    "\n",
    "Let's say we've transformed a data file by adding some new data, or cleaning it. We now have a cleaned data set that we can queue up for analysis. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have a cleaned data file, here represented by a small table\n",
    "\n",
    "cleaned_table = {'data':[['1979', '7102100', '1512', '213'],\n",
    "                         ['2001', '8024964', '1184', '148'],\n",
    "                        ['2009', '8223444', '1204', '178']]}\n",
    "\n",
    "with open(directory + '/cleaned_data/new_json.json', 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(cleaned_table, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Numpy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(directory + '/cleaned_data/new_numpy.npy', cleaned_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. SQLite**\n",
    "\n",
    "This operation will be straightforward from the concepts outlined above, with the added step that we need to create our database if it does not exist, and our table within the database.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We first establish a new database and connect to it\n",
    "\n",
    "conn_out = sqlite3.connect(directory + '/cleaned_data/cleaned_sql.db')\n",
    "cursor_out = conn_out.cursor()\n",
    "\n",
    "# Then we create a new table\n",
    "\n",
    "cursor_out.execute('''CREATE TABLE IF NOT EXISTS newsql\n",
    "                  (year text not null unique, nyc_population text, consumption text, per_capita text) \n",
    "               ''')\n",
    "\n",
    "for insert_row in cleaned_table['data']:\n",
    "    cursor_out.execute(\"INSERT INTO newsql VALUES (?,?,?,?)\", insert_row)\n",
    "\n",
    "conn_out.commit()\n",
    "conn_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. CSV with Pandas**\n",
    "\n",
    "Pandas also has a very quick way to move a dataframe into a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_df = pd.DataFrame(cleaned_table['data'], columns = ['year','nyc_population','consumption', 'per_capita'])\n",
    "\n",
    "cleaned_df.to_csv(directory + '/cleaned_data/new_df.csv', ',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "Finally, we can perform syntax cleaning operations in Python just as easily as in a program like Excel. In fact, if you are working with very large data ( > 1.2 million rows) you will simply not be able to use Excel or other spreadsheet programs to manipulate data and must depend on other methods.\n",
    "\n",
    "Here, let's take a look at a very simple data set (2 columns, 66 rows) consisting of the Significant Noncompliance List published by NYC Open Data: https://data.cityofnewyork.us/Environment/Significant-Noncompliance-List/xnje-s6zf\n",
    "\n",
    "If you preview the data, you'll notice that a date span has been combined into a single row cell, that there is some inconsistencies in how months are listed, and it implements a kind of \"footnote\" method, with starred/crossed establishment names referring to the following notes:\n",
    "\n",
    " - **These establishments are on the list for late reporting only.*\n",
    " - *†These establishments are Non-Significant Industrial Users.*\n",
    "\n",
    "How would we perform the following data cleaning operations:\n",
    "\n",
    " 1) Split the \"period\" column into two columns, a start_date and end_date column?\n",
    " 2) Standarize all spelling of months\n",
    " 3) Create a new columns conveying the information in the \"footnote\" marks?\n",
    " 4) Remove commas, periods, etc. from the establishment names\n",
    " 5) Ensure there is no whitespace or newlines on the ends of entries\n",
    " 6) Output the cleaned data as a CSV in the /cleaned_data folder\n",
    "\n",
    "Try this challenge using whatever data container you wish. You may want to consider a very simple one: we can turn the CSV into a list of lists by reading in the file, splitting it on the \", combination, and working with each value separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(directory + '/raw_data/nyc-noncompliancelist.csv') as dfile:\n",
    "    rows = dfile.readlines()\n",
    "\n",
    "for row in rows[1:]:            # Taking the rows as a list, but skipping the first header row\n",
    "    print(row.split('\",'))      # Splitting on the delimiter which we notice the escaped \" before it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Challenge: BPL Branches Data\n",
    " \n",
    "Time permitting, let's put our full list of skills together and see if we can extract a simplified dataset from this Brooklyn Public Library <a href=\"https://data.cityofnewyork.us/Recreation/BPL-Branches/xmzf-uf2w\">listing</a> of library branches and hours. Using the JSON formatted file available at https://www.bklynlibrary.org/locations/json, extract the name of each branch, its address, and a third column listing the total number of hours per week that the branch is open.  \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
